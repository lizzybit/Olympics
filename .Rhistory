install.packages("tidyverse")
library(tidyverse)
install.packages("here")
library(here)
install.packages("skimr")
library(skimr)
install.packages(janitor)
install.packages("janitor")
library(janitor)
install.packages("palmerspenguins")
install.packages("palmerpenguins")
library(palmerpenguins)
View(palmerpenguin)
View(palmerpenguins)
glimpse(palmerpenguins)
glimpse(palmerpenguins)
skim_without_charts(palmerpenguins)
skim_without_charts(penguins)
View(penguins)
glimpse(penguins)
filter(penguins, year = 2007)
filter(penguins, year = "2007")
filter(penguins, year == "2007")
filter(penguins, year == 2007)
filter(penguins, year == 2007) %>%
order by(-bill_length_mm) %>%
filter(penguins, year == 2007) %>%
order by(bill_length_mm) %>%
filter(penguins, year == 2007) %>%
order_by(-bill_length_mm) %>%
limit 10
filter(penguins, year == 2007) %>%
order_by(-bill_length_mm) %>%
limit (10)
filter(penguins, year == 2007) %>%
order_by(-bill_length_mm)
filter(penguins, year == 2007) %>%
order_by(bill_length_mm)
filter(penguins, year == 2007) %>%
arrange(bill_length_mm)
filter(penguins, year == 2007) %>%
arrange(-bill_length_mm)
penguins %>%
select(species)
penguins %>%
rename(island=island_new)
penguins %>%
rename(island_new=islands)
glimpse(penguins)
penguins %>%
rename(island_new=islands)
penguins %>%
rename(island_new=island)
plot(cnet)
y <- data.frame(data$first, data$second)
# Social Network Analysis
library(igraph)
install.packages("igraph")
library(igraph)
g1 <- graph(c("Amy", "Ram", "Ram", "Li", "Li", "Amy",
"Amy", "Li", "Kate", "Li"),
directed=T)
edge_betweenness(g1, directed=T, weights=NA)
# Social Network Analysis
install.packages("igraph")
library(igraph)
g <- graph(c(1,2,2,3,3,4,4,1),
directed = F,
n=7)
g1 <- graph(c("Amy", "Ram", "Ram", "Li", "Li", "Amy",
"Amy", "Li", "Kate", "Li"),
directed=T)
# Network measures
degree(g1, mode='all')
degree(g1, mode='in')
degree(g1, mode='out')
diameter(g1, directed=F, weights = NA)
edge_density(g1, loops = F)
ecount(g1)/(vcount(g1)*(vcount(g1)-1))
reciprocity(g1)
closeness(g1, mode='all', weights = NA)
betweenness(g1, directed=T, weights=NA)
edge_betweenness(g1, directed=T, weights=NA)
install.packages("igraph")
edge_betweenness(g1, directed=T, weights=NA)
# Social Network Analysis
install.packages("igraph")
library(igraph)
g <- graph(c(1,2,2,3,3,4,4,1),
directed = F,
n=7)
g1 <- graph(c("Amy", "Ram", "Ram", "Li", "Li", "Amy",
"Amy", "Li", "Kate", "Li"),
directed=T)
# Network measures
degree(g1, mode='all')
degree(g1, mode='in')
degree(g1, mode='out')
diameter(g1, directed=F, weights = NA)
edge_density(g1, loops = F)
ecount(g1)/(vcount(g1)*(vcount(g1)-1))
reciprocity(g1)
closeness(g1, mode='all', weights = NA)
betweenness(g1, directed=T, weights=NA)
edge_betweenness(g1, directed=T, weights=NA)
plot(g
vertex.color = "green",
g <- graph(c(1,2))
plot(g
vertex.color = "green",
g <- graph(c(1,2))
plot(g
vertex.color = "green",
plot(g,
vertex.color = "green",
vertex size = 40,
edge.color = 'red')
edge.color = 'red'')
plot(g,
vertex.color = "green",
vertex size = 40,
edge.color = "red")
g <- graph(c(1,2))
plot(g,
vertex.color = "green",
vertex size = 40,
edge.color = "red")
plot(g,
vertex.color = "green",
vertex size = 40,
edge.color = "red")
install.packages("igraph")
library(igraph)
g <- graph(c(1,2))
plot(g,
vertex.color = "green",
vertex size = 40,
edge.color = "red")
plot(g,
vertex.color = "green",
vertex size = 40,
plot(g,
vertex.color = "green",
vertex.size = 40,
edge.color = "red")
library(igraph)
g <- graph(c(1,2))
plot(g,
vertex.color = "green",
vertex.size = 40,
edge.color = "red")
install.packages("igraph")
library(igraph)
g <- graph(c(1,2,2,3,3,4,4,1))
plot(g,
vertex.color = "green",
vertex.size = 40,
edge.color = "red")
g <- graph(c(1,2,2,3,3,4,4,1))
plot(g,
vertex.color = "green",
vertex.size = 40,
edge.color = "red")
g <- graph(c(1,2,2,3,3,4,4,1),
directed = F)
plot(g,
vertex.color = "green",
vertex.size = 40,
edge.color = "red")
g <- graph(c(1,2,2,3,3,4,4,1),
directed = F,
n = 7)
g <- graph(c(1,2,2,3,3,4,4,1),
directed = F,
n = 7)
g <- graph(c(1,2,2,3,3,4,4,1),
directed = F,
n = 7)
plot(g,
vertex.color = "green",
vertex.size = 40,
edge.color = "red")
g[]
g1 <- graph(c("Liz", "Peter", "Peter", "Chris", "Chris", "Amy",
"Liz", "Chris", "Kate", "Chris"),
directed=T)
plot(g1,
vertex.color = "green",
vertex.size = 40,
edge.color = "red")
degree(g1, mode='all')
degree(g1, mode='in')
degree(g1, mode='out')
diameter(g1, directed=F, weights = NA)
edge_density(g1, loops = F)
ecount(g1)/(vcount(g1)*(vcount(g1)-1))
reciprocity(g1)
closeness(g1, mode='all', weights = NA)
betweenness(g1, directed=T, weights=NA)
edge_betweenness(g1, directed=T, weights=NA)
diameter(g1, directed=F, weights = NA)
edge_density(g1, loops = F)
ecount(g1)/(vcount(g1)*(vcount(g1)-1))
reciprocity(g1)
closeness(g1, mode='all', weights = NA)
betweenness(g1, directed=T, weights=NA)
edge_betweenness(g1, directed=T, weights=NA)
diameter(g1, directed=F, weights = NA)
edge_density(g1, loops = F)
ecount(g1)/(vcount(g1)*(vcount(g1)-1))
reciprocity(g1)
closeness(g1, mode='all', weights = NA)
betweenness(g1, directed=T, weights=NA)
edge_betweenness(g1, directed=T, weights=NA)
y <- data.frame(data$first, data$second)
data <- read.csv('/Users/elizabeth/Documents/GitHub/R/networkdata.csv', header=T)
y <- data.frame(data$first, data$second)
library(readr)
networkdata <- read_csv("Documents/GitHub/R/networkdata.csv")
View(networkdata)
View(data)
net <- graph.data.frame(y, directed=T)
V(net)$label <- V(net)$name
V(net)$degree <- degree(net)
hist(V(net)$degree)
plot(net)
plot(net,
vertex.color = rainbow(52),
vertex.size = V(net)$degree*0.4,
edge.arrow.size = 0.1,
layout=layout.fruchterman.reingold)
hs <- hub_score(net)$vector
as <- authority.score(net)$vector
par(mfrow=c(1,2))
set.seed(123)
plot(net,
vertex.size=hs*30,
main = 'Hubs',
vertex.color = rainbow(52),
edge.arrow.size=0.1,
layout = layout.kamada.kawai)
plot(net,
vertex.size=as*30,
main = 'Authorities',
vertex.color = rainbow(52),
edge.arrow.size=0.1,
layout = layout.kamada.kawai)
par(mfrow=c(1,1))
# Community detection
net <- graph.data.frame(y, directed = F)
cnet <- cluster_edge_betweenness(net)
plot(cnet)
net <- graph.data.frame(y, directed = F)
cnet <- cluster_edge_betweenness(net)
plot(cnet)
load("~/Downloads/ATT86285.RData")
install.packages("readr")
install.packages("sqldf")
install.packages("calibrate")
install.packages("repr")
install.packages("tidyverse")
library(readr)
library(sqldf)
library(calibrate)
library(repr)
library(tidyverse)
list.files(path = "/Users/elizabeth/Documents/GitHub/Simpsons")
data_fp = '/Users/elizabeth/Documents/GitHub/Simpsons'
head(episodes)
episodes_fp = '/Users/elizabeth/Documents/GitHub/Simpsons/simpsons_episodes.csv'
head(episodes)
install.packages("readxl")
library(readxl)
library(readxl)
## Download and install all required packages
install.packages("readr")
install.packages("sqldf")
install.packages("calibrate")
install.packages("repr")
install.packages("tidyverse")
install.packages("readxl")
library(readr)
library(sqldf)
library(calibrate)
library(repr)
library(tidyverse)
library(readxl)
install.packages("sqldf")
###########################################################
###########################################################
## Download and install all required packages
library(readr)
library(sqldf)
library(calibrate)
library(repr)
library(tidyverse)
library(readxl)
library(knitr)
library(rmarkdown)
library(mice)
###########################################################
###########################################################
## Import data
setwd("/Users/elizabeth/Documents/GitHub/Olympics")
getwd()
olympics <- read.csv("athlete_events.csv", header = TRUE)
a <- head(olympics)
kable(a, format =  'markdown')
dim(olympics)
str(olympics)
# Build a list of columns that will be used for imputation
cols_to_impute = c('Year', 'Age', 'Height', 'Weight')
# Create an imputation model using mice
imputation_model <- mice(olympics[, cols_to_impute])
# Impute missing values
imputed_data <- complete(imputation_model)
# Assign the imputed data back to the original DataFrame's columns
olympics[, cols_to_impute] <- imputed_data[, cols_to_impute]
###########################################################
###########################################################
## Clean Data
# 1. Find null values
b <- colSums(is.na(olympics))
kable(b, format =  'markdown')
# 2. Fill the missing values in the column Medal with string of 'DNW'
olympics$Medal[is.na(olympics$Medal)] <- "DNW"
sum(is.na(olympics$Medal))
# 3. Replace missing values in height, weight and age using mice
# Build a list of columns that will be used for imputation
cols_to_impute = c('Year', 'Age', 'Height', 'Weight')
# Create an imputation model using mice
imputation_model <- mice(olympics[, cols_to_impute])
# Impute missing values
imputed_data <- complete(imputation_model)
# Assign the imputed data back to the original DataFrame's columns
olympics[, cols_to_impute] <- imputed_data[, cols_to_impute]
c <- colSums(is.na(olympics))
kable(c, format =  'markdown')
# 4. Drop unused games column as it contains data already found in year and season column
olympics$Games <- NULL
###########################################################
###########################################################
## Exploratory Data Analysis
# 1. Look at the statistical summary of the numeric columns:
summary(olympics)
d <- summary(olympics[, sapply(olympics, is.numeric)])
kable(d, format =  'markdown')
# Plot the histograms for the age, weight and height values:
## Age:
ggplot(olympics, aes(x = Age)) +
geom_histogram(binwidth = 1, fill = "blue", color = "black") +
theme(plot.title = element_text(hjust = 0.5))+
labs(title = "Distribution of Athlete Age",
x = "Age",
y = "Count")
## Weight:
ggplot(olympics, aes(x = Weight)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
theme(plot.title = element_text(hjust = 0.5))+
labs(title = "Distribution of Athlete Weight",
x = "Weight",
y = "Count")
## Height:
ggplot(olympics, aes(x = Height)) +
geom_histogram(binwidth = 3, fill = "blue", color = "black") +
theme(plot.title = element_text(hjust = 0.5))+
labs(title = "Distribution of Athlete Height",
x = "Height",
y = "Count")
# Create a boxplot of age and highlight the outliers
## Age
ggplot(olympics, aes(y = Age)) +
geom_boxplot(outlier.shape = 19, outlier.size = 3) +
ylim(0, 100) +
theme(plot.title = element_text(hjust = 0.5))+
labs(title = "Age Distribution with Outliers",
x = "",
y = "Age")+
scale_x_continuous(breaks = c())
## Weight:
ggplot(olympics, aes(y = Weight)) +
geom_boxplot(outlier.shape = 19, outlier.size = 3) +
ylim(0, 220) +
theme(plot.title = element_text(hjust = 0.5))+
labs(title = "Weight Distribution with Outliers",
x = "",
y = "Weight")+
scale_x_continuous(breaks = c())
## Height:
ggplot(olympics, aes(y = Height)) +
geom_boxplot(outlier.shape = 19, outlier.size = 3) +
ylim(120, 230) +
theme(plot.title = element_text(hjust = 0.5))+
labs(title = "Height Distribution with Outliers",
x = "",
y = "Height")+
scale_x_continuous(breaks = c())
# Calculate of Outliers Bound
## Age
a_q1 <- quantile(olympics$Age, 0.25)
a_q3 <- quantile(olympics$Age, 0.75)
a_iqr <- a_q3 - a_q1
a_small <- a_q1 - 1.5 * a_iqr
a_high <- a_q3 + 1.5 * a_iqr
a_small
a_high
## Weight:
w_q1 <- quantile(olympics$Weight, 0.25)
w_q3 <- quantile(olympics$Weight, 0.75)
w_iqr <- w_q3 - w_q1
w_small <- w_q1 - 1.5 * w_iqr
w_high <- w_q3 + 1.5 * w_iqr
w_small
w_high
## Height:
h_q1 <- quantile(olympics$Height, 0.25)
h_q3 <- quantile(olympics$Height, 0.75)
h_iqr <- h_q3 - h_q1
h_small <- h_q1 - 1.5 * h_iqr
h_high <- h_q3 + 1.5 * h_iqr
h_small
h_high
## Find the sport(s) with the youngest athletes: Insert into read me
young <- (olympics$Age < (a_q1 - 1.5 * a_iqr))
olympics$Sport[young]
olympics[young, "Sport"] %>% table()
## Find the sport(s) with the oldest athletes:
old <- (olympics$Age < (a_q3 + 1.5 * a_iqr))
olympics$Sport[old]
olympics[old, "Sport"] %>% table()
## Find the sport(s) with the lighest athletes:
light <- (olympics$Weight < (w_q1 - 1.5 * w_iqr))
olympics$Sport[light]
olympics[light, "Sport"] %>% table()
## Find the sport(s) with the heaviest athletes:
heavy <- (olympics$Weight < (w_q3 + 1.5 * w_iqr))
olympics$Sport[heavy]
olympics[heavy, "Sport"] %>% table()
## Find the sport(s) with the shortest athletes:
short <- (olympics$Height < (h_q1 - 1.5 * h_iqr))
olympics$Sport[short]
olympics[short, "Sport"] %>% table()
## Find the sport(s) with the tallest athletes:
tall <- (olympics$Height < (h_q3 + 1.5 * h_iqr))
olympics$Sport[tall]
olympics[tall, "Sport"] %>% table()
# Compare the Mean Age, Weight and Height for Male and Female Athletes
olympics %>%
group_by(Sex) %>%
summarize(mean_age = mean(Age, na.rm = TRUE),
mean_height = mean(Height, na.rm = TRUE),
mean_weight = mean(Weight, na.rm = TRUE))
## Check the minimum, average, maximum Age, Height, Weight of Athletes in Each Year
e <- olympics %>%
group_by(Year) %>%
summarize(min_age = min(Age),
mean_age = mean(Age),
max_age = max(Age),
min_height = min(Weight),
mean_height = mean(Weight),
max_height = max(Weight),
min_weight = min(Height),
mean_weight = mean(Height),
max_weight = max(Height))
print(e, n = nrow(f))
f <- olympics %>%
arrange(Year) %>%
group_by(Sport) %>%
select(Year, Sport) %>%
slice(1)
print(f, n = nrow(e))
kable(f, format =  'markdown')
medals_by_country <- olympics %>%
group_by(NOC, Medal) %>%
summarise(count = n()) %>%
ungroup()
total_medals_by_country <- medals_by_country %>%
group_by(NOC) %>%
summarise(total_medals = sum(count)) %>%
arrange(desc(total_medals))
top_10_countries <- head(total_medals_by_country, 10)
head(total_medals_by_country, 10)
g <- head(total_medals_by_country, 10)
kable(g, format =  'markdown')
